{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f651281",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "s3-via-FUSE FITS subsetting benchmarking notebook. \n",
    "runs against objects generated using benchmark_case_generator.ipynb.\n",
    "\"\"\"\n",
    "import os\n",
    "from functools import partial\n",
    "from itertools import chain, product\n",
    "from typing import Callable\n",
    "\n",
    "from s3_fuse.bench_config import CASES\n",
    "from s3_fuse.handlers import get_cuts_from_files\n",
    "from s3_fuse.log_goofys import assemble_cut_log\n",
    "from s3_fuse.utilz import preload_target, Netstat, mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e77ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# how many mock fits files did we generate per case? \n",
    "# TODO: add a listobjects step?\n",
    "QUANTITY = 10\n",
    "\n",
    "# how many and what kind of slices should we cut out of these files?\n",
    "\n",
    "CUT_COUNTS = (1, 3)\n",
    "BOX_SIZES = (100, 250)\n",
    "CUT_CASES = {}\n",
    "for count, size in product(CUT_COUNTS, BOX_SIZES):\n",
    "    CUT_CASES[f\"{count}_{size}\"] = (count, size, size / 4)\n",
    "    \n",
    "    \n",
    "# note: this function is a setting\n",
    "def make_loaders(*loader_names: str) -> dict[str, Callable]:\n",
    "    \"\"\"\n",
    "    produce a mapping from FITS-loader names to callable load methods.\n",
    "    currently only three are defined.\n",
    "    \"\"\"\n",
    "    loaders = {}\n",
    "    for name in loader_names:\n",
    "        if name == \"astropy\":\n",
    "            import astropy.io.fits\n",
    "            loaders[name] = astropy.io.fits.open\n",
    "        elif name == \"fitsio\":\n",
    "            import fitsio\n",
    "            loaders[name] = fitsio.FITS\n",
    "        # \"greedy\" version of astropy.io.fits.open, which fully loads a file\n",
    "        # into memory before doing anything with it. a useful bench reference.\n",
    "        # note that fitsio.FITS will not accept filelike objects and cannot be\n",
    "        # wrapped in this way without modifying its C extensions.\n",
    "        elif name == \"greedy_astropy\":\n",
    "            import astropy.io.fits\n",
    "            loaders[name] = partial(preload_target, astropy.io.fits.open)\n",
    "    return loaders\n",
    "\n",
    "\n",
    "# select loaders as defined by the previous function\n",
    "LOADERS = make_loaders(\"astropy\", \"fitsio\", \"greedy_astropy\")\n",
    "\n",
    "# select FUSE backends\n",
    "BACKENDS = (\"s3fs\", \"goofys\")\n",
    "\n",
    "GENERAL_SETTINGS = {\n",
    "    # do we actually want the array elements?\n",
    "    \"return_cuts\": False,\n",
    "    # shared random seed for strict repeatability\n",
    "    \"seed\": 11111,\n",
    "    # make 'shallow' cuts from 3D arrays? if False, make 3D cuts across\n",
    "    # all bands; if True, randomly select a single band for each cut\n",
    "    \"shallow\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bfc30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# what directory on the local filesystem shall we use as a mountpoint?\n",
    "# (or where is the bucket mounted already if we're not remounting?)\n",
    "S3_ROOT = \"/mnt/s3\"\n",
    "# where will we write goofys log output? not important if we're not doing that.\n",
    "FUSE_LOGFILE = \"fuse.log\"\n",
    "# what is the name of our s3 bucket?\n",
    "BUCKET = \"great_bucket_full_of_fits_files\"\n",
    "\n",
    "\n",
    "S3_SETTINGS = {\n",
    "    \"mount_path\": S3_ROOT,\n",
    "    \"bucket\": BUCKET,\n",
    "    # remount the bucket on each cycle? (not doing so is cheating because of\n",
    "    # inode linking, etc.)\n",
    "    \"remount\": True,\n",
    "    # only matters with goofys: run goofys in debug mode and scratch its\n",
    "    # output to a log file.\n",
    "    \"verbose\": False,\n",
    "    # goofys writes its debug-mode output to stderr.\n",
    "    # set both of these handlers to None if you'd like to\n",
    "    # deactivate logging. this will break on verbose goofys output,\n",
    "    # however, because the test routine won't know to\n",
    "    # wait for goofys to mount the bucket.\n",
    "    # note that adding a stream handler to the goofys introduces a\n",
    "    # little overhead even if it's not writing anything, and\n",
    "    # that goofys may be noticeably slower when actually writing\n",
    "    # debug logs (it's very verbose)\n",
    "    \"stream_handlers\": {\"_out\": None, \"_err\": None},\n",
    "}\n",
    "\n",
    "\n",
    "BENCH_CASES = tuple(product(CUT_CASES.keys(), CASES.keys(), LOADERS.keys(), BACKENDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c29a95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### define the benchmark\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ff82d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    results = {}\n",
    "    netstat = Netstat()\n",
    "    for ix, case in enumerate(BENCH_CASES):\n",
    "        cut_setting, prefix, loader, backend = case\n",
    "        # TODO: hacky\n",
    "        if \"3hdu\" in prefix:\n",
    "            hdu_ix = 2\n",
    "        else:\n",
    "            hdu_ix = 1\n",
    "        # skip these cases on this run 0 -- TODO: should be an is_terrible()\n",
    "        # sort of function\n",
    "        if \"rice\" not in prefix.lower():\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n****case {ix}: {case}****\")\n",
    "        paths = [f\"{S3_ROOT}/{prefix}/{prefix}_{ix}.fits\" for ix in range(QUANTITY)]\n",
    "        case_kwargs = GENERAL_SETTINGS | {\n",
    "            \"paths\": paths,\n",
    "            \"loader\": LOADERS[loader],\n",
    "            \"cut_settings\": {\n",
    "                kwarg: val \n",
    "                for kwarg, val \n",
    "                in zip((\"cut_count\", \"box_size\", \"size_variance\"), CUT_CASES[cut_setting])\n",
    "            },\n",
    "            \"s3_settings\": S3_SETTINGS | {\"backend\": backend},\n",
    "            \"hdu_ix\": hdu_ix\n",
    "        }\n",
    "        netstat.update()\n",
    "        cuts, runtime, handler_log = get_cuts_from_files(**case_kwargs)\n",
    "        netstat.update()\n",
    "        # or could specify ens5 or eth0 or whatever if there is ambiguity. up to you.\n",
    "        volume = list(netstat.interval.values())[0]\n",
    "        representative_size = os.stat(paths[0]).st_size\n",
    "        ratio = volume / (representative_size * QUANTITY)\n",
    "        print(\n",
    "            f\"{round(mb(volume), 2)} MB transferred \"\n",
    "            f\"({round(ratio*100, 2)}% of approximate file volume)\"\n",
    "        )\n",
    "        results[case] = (\n",
    "            cuts, \n",
    "            runtime, \n",
    "            {\"volume\": volume, \"rep_size\": representative_size, \"ratio\": ratio}, \n",
    "            handler_log, \n",
    "            None\n",
    "        )\n",
    "    logs = {\n",
    "        case_name: assemble_cut_log(result)\n",
    "        for case_name, result in results.items()\n",
    "    }\n",
    "    return results, logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b429e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### run the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48517bfc",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results, logs = run_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}