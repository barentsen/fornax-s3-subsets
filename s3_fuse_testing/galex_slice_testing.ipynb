{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843dd82e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"galex-specific s3-via-FUSE FITS subsetting test and benchmarking notebook\"\"\"\n",
    "\n",
    "import os\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "from typing import Callable\n",
    "\n",
    "from s3_fuse.galex_utils import (\n",
    "    pick_galex_eclipses, get_galex_version_path\n",
    ")\n",
    "from s3_fuse.handlers import get_cuts_from_files\n",
    "from s3_fuse.log_goofys import assemble_cut_log\n",
    "from s3_fuse.utilz import preload_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78cc3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4914f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# what files shall we examine?\n",
    "GALEX_FILE_SELECTIONS = {\n",
    "    \"band\": \"NUV\",\n",
    "    \"depth\": 30,\n",
    "    \"eclipses\": pick_galex_eclipses(5, \"mislike\"),\n",
    "    # 'movie' or 'image'\n",
    "    \"obj\": \"image\"\n",
    "}\n",
    "\n",
    "# what image plane?\n",
    "IMAGE_PLANE = 'cnt'\n",
    "BASE_HDU_IX = {'cnt': 0, 'flag': 1, 'edge': 2}[IMAGE_PLANE]\n",
    "\n",
    "# how many and what kind of slices should we cut out of these files?\n",
    "CUT_SETTINGS = {\"cut_count\": 1, \"box_size\": 100, \"size_variance\": 25}\n",
    "\n",
    "GENERAL_SETTINGS = {\n",
    "    # do we actually want the array elements?\n",
    "    \"return_cuts\": True,\n",
    "    \"cut_settings\": CUT_SETTINGS,\n",
    "    # shared random seed for strict repeatability\n",
    "    \"seed\": 333,\n",
    "    # make 'shallow' cuts from 3D arrays? if False, make 3D cuts across\n",
    "    # all bands; if True, randomly select a single band for each cut\n",
    "    \"shallow\": True,\n",
    "}\n",
    "\n",
    "# what directory on the local filesystem shall we use as a mountpoint?\n",
    "# (or where is the bucket mounted already if we're not remounting?)\n",
    "S3_ROOT = \"/mnt/s3\"\n",
    "# where will we write goofys log output? not important if we're not doing that.\n",
    "FUSE_LOGFILE = \"fuse.log\"\n",
    "# what is the name of our s3 bucket?\n",
    "BUCKET = \"great_bucket_full_of_fits_files\"\n",
    "\n",
    "S3_SETTINGS = {\n",
    "    \"mount_path\": S3_ROOT,\n",
    "    \"bucket\": BUCKET,\n",
    "    # remount the bucket on each cycle? (not doing so is cheating because of\n",
    "    # inode linking, etc.)\n",
    "    \"remount\": True,\n",
    "    # whatever FUSE backend you're using needs to be installed on the system.\n",
    "    # has only been prototyped with s3fs and goofys, but others are likely\n",
    "    # to work. this is not important if you set remount to False and have\n",
    "    # already mounted the bucket.\n",
    "    \"backend\": \"goofys\",\n",
    "    # only matters with goofys: run goofys in debug mode and scratch its\n",
    "    # output to a log file.\n",
    "    \"verbose\": True,\n",
    "    # goofys writes its debug-mode output to stderr.\n",
    "    # set both of these handlers to None if you'd like to\n",
    "    # deactivate logging. this will break on verbose goofys output,\n",
    "    # however, because the test routine won't know to\n",
    "    # wait for goofys to mount the bucket.\n",
    "    # note that adding a stream handler to the goofys introduces a\n",
    "    # little overhead even if it's not writing anything, and\n",
    "    # that goofys may be noticeably slower when actually writing\n",
    "    # debug logs (it's very verbose)\n",
    "    \"stream_handlers\": {\"_out\": None, \"_err\": FUSE_LOGFILE},\n",
    "}\n",
    "\n",
    "# note: this function is a setting\n",
    "def make_loaders(*loader_names: str) -> dict[str, Callable]:\n",
    "    \"\"\"\n",
    "    produce a mapping from FITS-loader names to callable load methods.\n",
    "    currently only three are defined by default.\n",
    "    \"\"\"\n",
    "    loaders = {}\n",
    "    for name in loader_names:\n",
    "        if name == \"astropy\":\n",
    "            import astropy.io.fits\n",
    "            loaders[name] = astropy.io.fits.open\n",
    "        elif name == \"fitsio\":\n",
    "            import fitsio\n",
    "            loaders[name] = fitsio.FITS\n",
    "        # \"greedy\" version of astropy.io.fits.open, which fully loads a file\n",
    "        # into memory before doing anything with it. a useful bench reference.\n",
    "        # note that fitsio.FITS will not accept filelike objects and cannot be\n",
    "        # wrapped in this way without modifying its C extensions.\n",
    "        elif name == \"greedy_astropy\":\n",
    "            import astropy.io.fits\n",
    "            loaders[name] = partial(preload_target, astropy.io.fits.open)\n",
    "    return loaders\n",
    "\n",
    "# select loaders as defined by the previous function\n",
    "# LOADERS = make_loaders(\"astropy\", \"greedy_astropy\", \"fitsio\")\n",
    "LOADERS = make_loaders(\"astropy\")\n",
    "\n",
    "# what versions of compression do we want to look at? options are\n",
    "# gz, rice, none\n",
    "# VERSIONS = (\"none\", \"rice\")\n",
    "VERSIONS = (\"none\",)\n",
    "\n",
    "# note: this function is a setting\n",
    "def is_terrible(loader_name, version):\n",
    "    \"\"\"ignore these cases: checking them is a waste of time\"\"\"\n",
    "    if (\n",
    "        (GALEX_FILE_SELECTIONS[\"obj\"] == \"movie\")\n",
    "        and (version in (\"gz\", \"none\"))\n",
    "        and (S3_SETTINGS[\"backend\"] == \"goofys\")\n",
    "        and (loader_name == \"fitsio\")\n",
    "    ):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8261b7e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### define the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949a08d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper function\n",
    "def get_test_paths(eclipses, band, depth, obj, version):\n",
    "    return [\n",
    "        get_galex_version_path(eclipse, band, depth, obj, version, S3_ROOT)\n",
    "        for eclipse in eclipses\n",
    "    ]\n",
    "    \n",
    "def run_test():\n",
    "    results = {}\n",
    "    for loader_name, version in product(LOADERS.keys(), VERSIONS):\n",
    "        case_name = f\"{loader_name} {version}\"\n",
    "        print(f\"\\n****checking {case_name}****\")\n",
    "        if is_terrible(loader_name, version):\n",
    "            print(\"case marked as terrible, skipping\")\n",
    "            continue\n",
    "        paths = get_test_paths(**GALEX_FILE_SELECTIONS, version=version)\n",
    "        case_kwargs = GENERAL_SETTINGS | {\n",
    "            \"paths\": paths,\n",
    "            \"loader\": LOADERS[loader_name],\n",
    "            \"cut_settings\": CUT_SETTINGS,\n",
    "            \"s3_settings\": S3_SETTINGS,\n",
    "            \"hdu_ix\": BASE_HDU_IX + 1 if version == \"rice\" else BASE_HDU_IX,\n",
    "        }\n",
    "        cuts, runtime, handler_log = get_cuts_from_files(**case_kwargs)\n",
    "        # TODO: sloppy\n",
    "        if S3_SETTINGS[\"stream_handlers\"][\"_err\"] is not None:\n",
    "            with open(FUSE_LOGFILE) as logstream:\n",
    "                fuse_log = logstream.read()\n",
    "            os.remove(FUSE_LOGFILE)\n",
    "        else:\n",
    "            fuse_log = None\n",
    "        results[case_name] = cuts, runtime, None, handler_log, fuse_log\n",
    "    logs = {\n",
    "        case_name: assemble_cut_log(result)\n",
    "        for case_name, result in results.items()\n",
    "    }\n",
    "    return results, logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ed505",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### run the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe85025",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results, logs = run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb82a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### look at logs, returned data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c80cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cuts, runtime, handler_log, fuse_log = results['astropy none']\n",
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89118816",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this log contains timestamped records of all 'handler' operations\n",
    "# like mounting the bucket, initializing a FITS object, etc.\n",
    "# if goofys was in debug/verbose mode, it will also contain\n",
    "# all S3 requests and aliased-throuugh-FUSE http stream reads.\n",
    "import pandas as pd\n",
    "\n",
    "log_df = pd.DataFrame(\n",
    "    logs[\"astropy none\"]\n",
    ").sort_values(by=\"time\").reset_index(drop=True)\n",
    "log_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}