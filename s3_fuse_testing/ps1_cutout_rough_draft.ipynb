{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f70e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from cytoolz import groupby\n",
    "from cytoolz.curried import get\n",
    "from gPhoton.pretty import print_stats\n",
    "from killscreen.monitors import Netstat, Stopwatch\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.csv\n",
    "from pyarrow import parquet\n",
    "\n",
    "from s3_fuse.mount_s3 import mount_bucket\n",
    "from s3_fuse.ps1_utils import prune_ps1_catalog, get_ps1_cutouts\n",
    "from s3_fuse.utilz import make_loaders, sample_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eed92e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 'configuration'\n",
    "\n",
    "BUCKET = 'nishapur'\n",
    "S3_ROOT = '/mnt/s3'\n",
    "\n",
    "mount_bucket(\n",
    "    backend=\"goofys\", remount=False, mount_path=S3_ROOT, bucket=BUCKET\n",
    ")\n",
    "\n",
    "# desired cutout side length in degrees\n",
    "CUTOUT_SIDE_LENGTH = 60 / 3600\n",
    "\n",
    "# which PS1 bands are we looking at? (currently only g and z are staged.)\n",
    "PS1_BANDS = (\"g\", \"z\")\n",
    "# shall we do GALEX stuff?\n",
    "DO_GALEX_STUFF = False\n",
    "\n",
    "# select loaders -- options are \"astropy\", \"fitsio\", \"greedy_astropy\", \"greedy_fitsio\"\n",
    "# NOTE: because all the files this particular notebook is looking\n",
    "# at are RICE-compressed, there is unlikely to be much difference\n",
    "# between astropy and greedy_astropy -- astropy does not support\n",
    "# loading individual tiles from a a tile-compressed FITS file.\n",
    "LOADERS = make_loaders(\"greedy_fitsio\", \"fitsio\",)\n",
    "\n",
    "def cleanup_loader(loader_name):\n",
    "    if \"greedy\" in loader_name:\n",
    "        shutil.rmtree(\"/dev/shm/slicetemp\", ignore_errors=True)\n",
    "        \n",
    "def parse_topline(log):\n",
    "    total = next(reversed(log.values()))\n",
    "    summary, duration, volume = total.split(\",\")\n",
    "    cut_count = int(re.search(r\"\\d+\", summary).group())\n",
    "    seconds = float(re.search(r\"\\d+\\.?\\d+\", duration).group())\n",
    "    megabytes = float(re.search(r\"\\d+\\.?\\d+\", volume).group())\n",
    "    rate = cut_count / seconds\n",
    "    weight = megabytes / cut_count\n",
    "    return round(rate, 2), round(weight, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99697a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# catalog of PS1 extragalactic extended objects, including explicit \n",
    "# assignments to PS1 stack image projection / sky cells and GALEX \n",
    "# eclipse numbers\n",
    "catalog_fn = \"ps1_extragalactic_skycells_eclipses.parquet\"\n",
    "if not Path(catalog_fn).exists():\n",
    "    shutil.copy(\n",
    "        Path(S3_ROOT, \"ps1/metadata\", catalog_fn),\n",
    "        Path(catalog_fn)\n",
    "    )\n",
    "catalog = parquet.read_table(catalog_fn)\n",
    "\n",
    "# for this demo, we only staged a subset of those PS1 stack images \n",
    "# (all of them at all 5 bands would be > 80 TB). this is a list of \n",
    "# the (randomly selected) projection and sky cells we staged.\n",
    "test_cell_fn = \"ps1_extragalactic_skycells_eclipses_1k_cell_subset.csv\"\n",
    "arbitrary_test_cells = (\n",
    "    pa.csv\n",
    "    .read_csv(Path(S3_ROOT, \"ps1/metadata\", test_cell_fn))\n",
    "    .cast(pa.schema([(\"proj_cell\", pa.uint16()), (\"sky_cell\", pa.uint8())]))\n",
    ")\n",
    "small_catalog = prune_ps1_catalog(catalog, arbitrary_test_cells)\n",
    "\n",
    "# and a little pruning on GALEX: this is a table of actually-existing MIS-like \n",
    "# images by eclipse number, excluding eclipses with data currently flagged as bad\n",
    "extant_mislike = pd.read_csv(Path(S3_ROOT, \"extant_mislike_eclipses.csv\"))['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae7390",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# how many objects shall we collect slices for? (785510 are available in this test set)\n",
    "TARGET_COUNT = 800\n",
    "# optional parameter -- restrict the total number of PS1 source cells to test the \n",
    "# performance effects of denser sampling (1000 total PS1 cells are available in this test set).\n",
    "# note that the number of actual images accessed is a factor of both the number of cells\n",
    "# and the number of bands under consideration.\n",
    "# if GALEX fusion is taking place, this will also indirectly\n",
    "# restrict the number of GALEX images.\n",
    "MAX_CELL_COUNT = 4\n",
    "if MAX_CELL_COUNT is not None:\n",
    "    test_catalog = prune_ps1_catalog(\n",
    "        small_catalog, sample_table(arbitrary_test_cells, k=MAX_CELL_COUNT)\n",
    "    )\n",
    "else:\n",
    "    test_catalog = small_catalog\n",
    "targets = sample_table(test_catalog, k=TARGET_COUNT).to_pylist()\n",
    "ps1_stacks = set(map(get(['proj_cell', 'sky_cell']), targets))\n",
    "galex_eclipses = {\n",
    "    e for e in tuple(chain.from_iterable(map(get('galex'), targets)))\n",
    "    if e in extant_mislike.values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per-loader performance-tuning parameters\n",
    "# image_chunksize: how many images shall we initialize at once?\n",
    "# image_threads: how many threads shall we init with in parallel? (None to disable.)\n",
    "# cut_threads: how many threads shall we cut with in parallel? (None to disable.)\n",
    "TUNING = {\n",
    "    \"fitsio\": {\"image_chunksize\": 40, \"image_threads\": 4, \"cut_threads\": 4},\n",
    "    \"greedy_fitsio\": {\"image_chunksize\": 40, \"image_threads\": 4, \"cut_threads\": None},\n",
    "    \"default\": {\"image_chunksize\": 40, \"image_threads\": 4, \"cut_threads\": 4},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = {}\n",
    "for loader_name, loader in LOADERS.items():\n",
    "    # remount bucket to avoid \"cheating\"\n",
    "    print(f\"----testing {loader_name}----\")\n",
    "    mount_bucket(\n",
    "        backend=\"goofys\", remount=True, mount_path=S3_ROOT, bucket=BUCKET\n",
    "    )\n",
    "    tuning_params = TUNING[loader_name] if loader_name in TUNING.keys() else TUNING[\"default\"]\n",
    "    cuts, logs[loader_name] = get_ps1_cutouts(\n",
    "        ps1_stacks, \n",
    "        loader, \n",
    "        targets, \n",
    "        CUTOUT_SIDE_LENGTH, \n",
    "        f\"{S3_ROOT}/ps1\", \n",
    "        PS1_BANDS,\n",
    "        verbose=2,\n",
    "        **tuning_params\n",
    "    )\n",
    "    cleanup_loader(loader_name)\n",
    "    rate, weight = parse_topline(logs[loader_name])\n",
    "    print(f\"{rate} cutouts/s, {weight} MB / cutout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "watch = Stopwatch()\n",
    "req_cutouts = {}\n",
    "for target in targets[:10]:\n",
    "    req_cutouts[target['obj_id']] = request_ps1_cutout(\n",
    "        ps1_stack_path(target['proj_cell'], target['sky_cell'], band),\n",
    "        target['ra'],\n",
    "        target['dec'],\n",
    "        CUTOUT_SIDE_LENGTH * 3600,\n",
    "        \"fits\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b6087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1cabd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca768c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66525e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05878b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be made into a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps1_groups = groupby(get(['proj_cell', 'sky_cell']), targets)\n",
    "ps1_cutouts = {}\n",
    "log = {}\n",
    "for loader_name, loader in LOADERS.items():\n",
    "    # remount bucket to avoid 'cheating'\n",
    "    mount_bucket(\n",
    "        backend=\"goofys\", remount=True, mount_path=S3_ROOT, bucket=BUCKET\n",
    "    )\n",
    "    print(f\"\\n--------testing {loader_name}--------\\n\")\n",
    "    outer_stat = print_stats(Stopwatch(silent=True), Netstat())\n",
    "    for stack in ps1_stacks:\n",
    "        image_targets = ps1_groups[stack]\n",
    "        cutouts, _, stack_log = get_ps1_cutouts(\n",
    "            image_targets, \n",
    "            loader,\n",
    "            PS1_BANDS, \n",
    "            CUTOUT_SIDE_LENGTH, \n",
    "            f\"{S3_ROOT}/ps1\",\n",
    "            verbose=1\n",
    "        )\n",
    "        ps1_cutouts |= cutouts\n",
    "        log |= stack_log\n",
    "    print(\n",
    "        f\"acquired {len(targets) * len(PS1_BANDS)} cutouts from \"\n",
    "        f\"{len(ps1_stacks) * len(PS1_BANDS)} images,{outer_stat()}\"\n",
    "    )\n",
    "    if DO_GALEX_STUFF is True:\n",
    "\n",
    "        galex_slices = defaultdict(list)\n",
    "        systems = {}\n",
    "        for eclipse in galex_eclipses:\n",
    "            eclipse_targets = tuple(filter(lambda t: eclipse in t['galex'], targets))\n",
    "            slices, system = get_galex_rice_slices(\n",
    "                eclipse, eclipse_targets, CUTOUT_SIDE_LENGTH, S3_ROOT, watch, stat\n",
    "            )\n",
    "            systems[eclipse] = system\n",
    "            for k, v in slices.items():\n",
    "                galex_slices[k].append(v)\n",
    "        print(f\"acquired GALEX cutouts,{outer_stat()}\")\n",
    "        galex_coadds = {}\n",
    "        print(\n",
    "            f\"...coadding {len(tuple(chain.from_iterable(galex_slices.values())))} image slices...\", \n",
    "            end=\"\"\n",
    "        )\n",
    "        for obj_id, images in galex_slices.items():\n",
    "            if len(images) == 0:\n",
    "                print(\"all GALEX images for {obj_id} are bad, skipping\")\n",
    "            galex_coadds[obj_id] = coadd_image_slices(images, systems)\n",
    "        print(f\"coadded GALEX cutouts,{outer_stat()}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94728867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa7b25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ps1_groups = groupby(get(['proj_cell', 'sky_cell']), targets)\n",
    "ps1_cutouts = {}\n",
    "log = {}\n",
    "for loader_name, loader in LOADERS.items():\n",
    "    # remount bucket to avoid 'cheating'\n",
    "    mount_bucket(\n",
    "        backend=\"goofys\", remount=True, mount_path=S3_ROOT, bucket=BUCKET\n",
    "    )\n",
    "    print(f\"\\n--------testing {loader_name}--------\\n\")\n",
    "    outer_stat = print_stats(Stopwatch(silent=True), Netstat())\n",
    "    for stack in ps1_stacks:\n",
    "        image_targets = ps1_groups[stack]\n",
    "        cutouts, _, stack_log = get_ps1_cutouts(\n",
    "            image_targets, \n",
    "            loader,\n",
    "            PS1_BANDS, \n",
    "            CUTOUT_SIDE_LENGTH, \n",
    "            f\"{S3_ROOT}/ps1\",\n",
    "            verbose=1\n",
    "        )\n",
    "        ps1_cutouts |= cutouts\n",
    "        log |= stack_log\n",
    "    print(\n",
    "        f\"acquired {len(targets) * len(PS1_BANDS)} cutouts from \"\n",
    "        f\"{len(ps1_stacks) * len(PS1_BANDS)} images,{outer_stat()}\"\n",
    "    )\n",
    "    if DO_GALEX_STUFF is True:\n",
    "\n",
    "        galex_slices = defaultdict(list)\n",
    "        systems = {}\n",
    "        for eclipse in galex_eclipses:\n",
    "            eclipse_targets = tuple(filter(lambda t: eclipse in t['galex'], targets))\n",
    "            slices, system = get_galex_rice_slices(\n",
    "                eclipse, eclipse_targets, CUTOUT_SIDE_LENGTH, S3_ROOT, watch, stat\n",
    "            )\n",
    "            systems[eclipse] = system\n",
    "            for k, v in slices.items():\n",
    "                galex_slices[k].append(v)\n",
    "        print(f\"acquired GALEX cutouts,{outer_stat()}\")\n",
    "        galex_coadds = {}\n",
    "        print(\n",
    "            f\"...coadding {len(tuple(chain.from_iterable(galex_slices.values())))} image slices...\", \n",
    "            end=\"\"\n",
    "        )\n",
    "        for obj_id, images in galex_slices.items():\n",
    "            if len(images) == 0:\n",
    "                print(\"all GALEX images for {obj_id} are bad, skipping\")\n",
    "            galex_coadds[obj_id] = coadd_image_slices(images, systems)\n",
    "        print(f\"coadded GALEX cutouts,{outer_stat()}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5921ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3_fuse.ps1_utils import request_ps1_cutout, request_ps1_filenames, ps1_stack_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08649b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_ps1_cutout??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9571871",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5182d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in PS1_BANDS:\n",
    "    for target in targets:\n",
    "        filename = \n",
    "        cutout = request_ps1_cutout(\n",
    "        ps1_stack_path(target['proj_cell'], target['sky_cell'], band)    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
