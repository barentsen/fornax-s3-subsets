{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f651281",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from killscreen.utilities import roundstring\n",
    "\n",
    "from s3_fuse.bench_utils import (\n",
    "    summarize_stat,\n",
    "    check_existing_benchmarks,\n",
    "    dump_bandwidth_allowance_metrics,\n",
    "    dump_throwaway_results\n",
    ")\n",
    "from s3_fuse.handlers import interpret_benchmark_instructions, execute_test_case, process_bench_stats\n",
    "from s3_fuse.mount_s3 import mount_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "simple execution environment for dataset benchmarking. executes benchmarks defined in the benchmark_settings module.\n",
    "\n",
    "important notes:\n",
    "* the `fsspec`-based \"s3\" and \"s3_section\" loaders will only function on the barentsen/cloud-support astropy branch.\n",
    "* other loaders will only function if `goofys` is executable from the user's path.\n",
    "* attempts to access private buckets, via either `goofys` or `fsspec`, will use credentials stored in ~/.aws/credentials.\n",
    "* bandwidth throttling will only work if `wondershaper` is executable from the user's path, the user is a sudoer, and the user has no `sudo` password (like \"ubuntu\" in stock AWS EC2 Ubuntu images).\n",
    "* this currently assumes that the network interface of interest is named \"ens5\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293984e",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SETTINGS = {\n",
    "    # directory goofys will use as a mount point for buckets\n",
    "    \"mountpoint\": \"/mnt/s3/\",\n",
    "    # max files -- will use the top n_files elements of the TEST_FILES attribute of\n",
    "    # each benchmark module (unless less than n_files are given in TEST_FILES!)\n",
    "    \"n_files\": 25,\n",
    "    # do we actually want to look at the cuts? probably not in big bulk benchmarks,\n",
    "    # but can be useful for diagnostics or if you want a screensaver or whatever.\n",
    "    \"return_cuts\": False,\n",
    "    # rng seed for consistent execution w/out having to explicitly define a very long\n",
    "    # list of rectangles\n",
    "    \"seed\": 123456,\n",
    "    # these values are given in kilobits per second. None means unthrottled.\n",
    "    # if you don't pass this key, there won't be any throttling in any test.\n",
    "    \"bandwidth\": (None, 100 * 1000)\n",
    "}\n",
    "# these correspond to the names of submodules of the benchmark_settings module\n",
    "BENCHMARK_NAMES = (\n",
    "    \"hst\", \"panstarrs\", \"galex_rice\", \"jwst_crf\", \"tesscut\", \"galex_gzip\", \"hst_big\", \n",
    ")\n",
    "# if there is an existing result file corresponding to a particular test case, shall\n",
    "# we run it again (wiincrementing suffixes attached to outputs?)\n",
    "DUPLICATE_BENCHMARKS = False\n",
    "# where shall we write benchmark results?\n",
    "METRIC_DIRECTORY = \"bench_results\"\n",
    "# how many throwaway tests should we run every time we switch the specific set of cuts we're using?\n",
    "# this is intended to juice S3 serverside caching so that earlier-in-order\n",
    "# cases aren't 'penalized' without us having to either make a separate copy of all S3 objects\n",
    "# for every test case, select random objects from a larger corpus, or wait a long time (60s - 15m, ish)\n",
    "# between each test case.\n",
    "# this is spooky, because it's a black box -- we have no way to seriously interrogate\n",
    "# how this works. It can affect run times by a factor of 2-3 in many cases, though.\n",
    "N_THROWAWAYS = 3\n",
    "# \"benchmarks\" contains instructions for each test case\n",
    "benchmarks = {\n",
    "    name: interpret_benchmark_instructions(name, SETTINGS)\n",
    "    for name in BENCHMARK_NAMES\n",
    "}\n",
    "# partially-evaluated S3 mount function, for convenience\n",
    "remount = partial(\n",
    "    mount_bucket, \"goofys\", SETTINGS['mountpoint'], remount=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5f8a5",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "execute all benchmarks in a loop and save results. you can mess with this cell\n",
    "to pretty straightforwardly look at only certain categories of cases,\n",
    "suppress results, etc.\n",
    "\"\"\"\n",
    "logs = {}\n",
    "for benchmark_name, benchmark in benchmarks.items():\n",
    "    previous = {}\n",
    "    for case in benchmark:\n",
    "        skip, suffix = check_existing_benchmarks(case['title'], DUPLICATE_BENCHMARKS, METRIC_DIRECTORY)\n",
    "        if skip is True:\n",
    "            continue\n",
    "        cuts, stat, log, throwaways = execute_test_case(case, previous, remount, N_THROWAWAYS)\n",
    "        print(roundstring(summarize_stat(stat)) + \"\\n\")\n",
    "        logs[f\"{case['title']}\"] = log\n",
    "        process_bench_stats(log, case, benchmark_name).to_csv(\n",
    "            Path(METRIC_DIRECTORY, f\"{case['title']}_{suffix}.csv\"), index=None\n",
    "        )\n",
    "        dump_bandwidth_allowance_metrics(case['title'], suffix, METRIC_DIRECTORY)\n",
    "        dump_throwaway_results(throwaways, case['title'], suffix, METRIC_DIRECTORY)\n",
    "        previous = case\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}